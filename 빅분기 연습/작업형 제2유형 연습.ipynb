{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T2. Exam Question (2nd round) / 기출 (2회차) : E-Commerce Shipping Data\n",
    "* 성능이 우수한 예측모형을 구축하기 위해서는 적절한 데이터 전처리, 피처엔지니어링, 분류알고리즘, 하이퍼파라미터 튜닝, 모형 앙상블 등이 수반되어야 한다.\n",
    "* 수험번호.csv파일이 만들어지도록 코드를 제출한다.\n",
    "* 제출한 모델의 성능은 ROC-AUC형태로 읽어드린다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8799, 11), (2200, 11), (8799, 2), (2200, 2))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 시험환경 세팅 (코드 변경 X)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def exam_data_load(df, target, id_name=\"\", null_name=\"\"):\n",
    "    if id_name == \"\":\n",
    "        df = df.reset_index().rename(columns={\"index\": \"id\"})\n",
    "        id_name = 'id'\n",
    "    else:\n",
    "        id_name = id_name\n",
    "    \n",
    "    if null_name != \"\":\n",
    "        df[df == null_name] = np.nan\n",
    "    \n",
    "    X_train, X_test = train_test_split(df, test_size=0.2, random_state=2021)\n",
    "    \n",
    "    y_train = X_train[[id_name, target]]\n",
    "    X_train = X_train.drop(columns=[target])\n",
    "\n",
    "    \n",
    "    y_test = X_test[[id_name, target]]\n",
    "    X_test = X_test.drop(columns=[target])\n",
    "    return X_train, X_test, y_train, y_test \n",
    "    \n",
    "df = pd.read_csv(\"./datasets/customer-analytics/Train.csv\")\n",
    "X_train, X_test, y_train, y_test = exam_data_load(df, target='Reached.on.Time_Y.N', id_name='ID')\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop([\"Warehouse_block\",\"Mode_of_Shipment\", \"Gender\", \"Product_importance\"], axis=1,inplace=True)\n",
    "X_test.drop([\"Warehouse_block\",\"Mode_of_Shipment\", \"Gender\", \"Product_importance\"], axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_id = X_train.pop('ID')\n",
    "X_test_id  = X_test.pop('ID')\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(X_train, y_train[\"Reached.on.Time_Y.N\"])\n",
    "pred = rf.predict(X_test)\n",
    "pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Reached.on.Time_Y.N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4732</th>\n",
       "      <td>4733</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2039</th>\n",
       "      <td>2040</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5113</th>\n",
       "      <td>5114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2360</th>\n",
       "      <td>2361</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>5996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  Reached.on.Time_Y.N\n",
       "4732  4733                    1\n",
       "2039  2040                    1\n",
       "5113  5114                    1\n",
       "2360  2361                    1\n",
       "5995  5996                    0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission =pd.DataFrame({\"ID\":X_test_id,\"Reached.on.Time_Y.N\":pred})\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62.95"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(rf.score(X_test, y_test['Reached.on.Time_Y.N']) * 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T2. Exercise / 예시문제 : 백화점고객의 1년간 데이터 (dataq 공식 예제)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05081002, 0.0200896 , 0.01216845, ..., 0.13729977, 0.52702703,\n",
       "        0.10240964],\n",
       "       [0.02296577, 0.00722639, 0.00053215, ..., 0.02371542, 0.        ,\n",
       "        0.0060241 ],\n",
       "       [0.02341239, 0.00652602, 0.        , ..., 0.04743083, 0.        ,\n",
       "        0.0060241 ],\n",
       "       ...,\n",
       "       [0.0220982 , 0.00432203, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.0228559 , 0.00562554, 0.        , ..., 0.        , 0.        ,\n",
       "        0.23493976],\n",
       "       [0.13281818, 0.05301985, 0.01059507, ..., 0.06740171, 0.4673913 ,\n",
       "        0.04819277]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "X_train = pd.read_csv(\"./data/pdq/X_train.csv\", encoding=\"CP949\")\n",
    "X_test = pd.read_csv(\"./data/pdq/X_test.csv\", encoding=\"CP949\")\n",
    "y_train = pd.read_csv(\"./data/pdq/y_train.csv\", encoding=\"CP949\")\n",
    "ids = X_test[\"cust_id\"]\n",
    "\n",
    "\n",
    "# 데이터 확인\n",
    "# X_train.info()\n",
    "# X_train.describe()\n",
    "# print(X_train.isnull().sum())\n",
    "# print(X_test.isnull().sum())\n",
    "\n",
    "# 데이터 전처리\n",
    "X_train[\"환불금액\"].fillna(0,inplace=True)\n",
    "X_test[\"환불금액\"].fillna(0, inplace=True)\n",
    "X_train=X_train.drop([\"cust_id\", \"주구매상품\", \"주구매지점\"], axis=1)\n",
    "X_test=X_test.drop([\"cust_id\", \"주구매상품\", \"주구매지점\"], axis=1)\n",
    "# X_train = pd.get_dummies(X_train)\n",
    "# X_test =pd.get_dummies(X_test)\n",
    "\n",
    "\n",
    "mx = MinMaxScaler()\n",
    "mx.fit(X_train)\n",
    "st_train = mx.transform(X_train)\n",
    "st_test = mx.transform(X_test)\n",
    "\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(st_train, y_train[\"gender\"], test_size=0.2, random_state=1)\n",
    "\n",
    "# xgb=XGBClassifier(n_estimators=500, max_depth=5, learning_rate=0.02, objective='binary:logistic')\n",
    "# xgb.fit(X_tr, y_tr, early_stopping_rounds=100, eval_metric='auc', eval_set=[(X_val,y_val)], verbose=False)\n",
    "\n",
    "# rf = RandomForestClassifier(n_estimators=300,max_depth=8,min_samples_leaf=5,random_state=1)\n",
    "# rf.fit(X_tr, y_tr)\n",
    "\n",
    "# dt = DecisionTreeClassifier(max_depth=5, random_state=1)\n",
    "# dt.fit(X_tr, y_tr)\n",
    "\n",
    "# sv = SVC()\n",
    "# sv.fit(X_tr, y_tr)\n",
    "\n",
    "\n",
    " # score확인해보기\n",
    "\n",
    "# prediction = rf.predict(X_val)\n",
    "\n",
    "# print(accuracy_score(y_val, prediction))\n",
    "\n",
    "# pred=rf.predict(st_test)\n",
    "\n",
    "# submission = pd.DataFrame({\"cust_id\":ids, \"gender\":pred})\n",
    "# submission.to_csv(\"./data/013455.csv\", index=False)\n",
    "# print(help(RandomForestClassifier()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  T2-1 titanic 예측 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9820022497187851\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, mean_squared_error\n",
    "\n",
    "\n",
    "X_train = pd.read_csv(\"./data/titanic/train.csv\")\n",
    "X_test = pd.read_csv(\"./data/titanic/test.csv\")\n",
    "X_train.dropna(subset=[\"Embarked\"], inplace=True)\n",
    "X_test.dropna(subset=[\"Fare\"], inplace=True)\n",
    "# X_train.shape\n",
    "ids=X_test[\"PassengerId\"]\n",
    "y_train = X_train[\"Survived\"]\n",
    "\n",
    "\n",
    "X_train.drop([\"PassengerId\",\"Ticket\", \"Cabin\", \"Name\",\"Survived\"], axis=1, inplace=True)\n",
    "X_test.drop([\"PassengerId\",\"Ticket\", \"Cabin\", \"Name\"], axis=1, inplace=True)\n",
    "\n",
    "X_train[\"Age\"].fillna(X_train[\"Age\"].mean(), inplace=True)\n",
    "X_test[\"Age\"].fillna(X_test[\"Age\"].mean(), inplace=True)\n",
    "\n",
    "# # 전처리 train Age, Embarked     test Age, Fare\n",
    "\n",
    "\n",
    "columns=[\"Embarked\",\"Sex\"]\n",
    "for col in columns:\n",
    "    lb=LabelEncoder()\n",
    "    X_train[col]=lb.fit_transform(X_train[col])\n",
    "    X_test[col]=lb.fit_transform(X_test[col])\n",
    "    \n",
    "\n",
    "# lb= LabelEncoder()\n",
    "# lb.fit(X_train[\"Embarked\"])\n",
    "# X_train[\"Embarked\"]=lb.transform(X_train[\"Embarked\"])\n",
    "# X_test[\"Embarked\"]=lb.transform(X_test[\"Embarked\"])\n",
    "# lb.fit(X_train[\"Sex\"])\n",
    "# X_train[\"Sex\"]=lb.transform(X_test[\"Sex\"])\n",
    "# X_test[\"Sex\"]=lb.transform(X_test[\"Sex\"])\n",
    "\n",
    "mx = MinMaxScaler()\n",
    "mx.fit(X_train)\n",
    "X_train = mx.transform(X_train)\n",
    "X_test =mx.transform(X_test)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred= rf.predict(X_test)\n",
    "print(rf.score(X_train,y_train))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T2-2. Pima Indians Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도는:0.721\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "data= pd.read_csv(\"./datasets/pimaid/diabetes.csv\")\n",
    "\n",
    "y = data[\"Outcome\"]\n",
    "data.drop([\"Outcome\"], axis=1, inplace=True)\n",
    "\n",
    "# 데이터 전처리\n",
    "# 데이터 결측값이나 이상치 확인하는 코드 작성해서 확인하고 주석 처리하기\n",
    "\n",
    "# data.info()\n",
    "# data.describe()\n",
    "# data.isnull().sum()\n",
    "\n",
    "# features=[ \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\"]\n",
    "# for i in features:\n",
    "#    zero = data[data[i]==0][i].count()\n",
    "#    print(i, zero)\n",
    "\n",
    "data[\"SkinThickness\"] = data[\"SkinThickness\"].replace(0, data[\"SkinThickness\"].mean())\n",
    "data[\"Insulin\"] = data[\"Insulin\"].replace(0, data[\"Insulin\"].mean())\n",
    "mm = MinMaxScaler()\n",
    "mm.fit_transform(data)\n",
    "\n",
    "\n",
    "X_train,X_test, y_train, y_test= train_test_split(data,y ,test_size=0.2, random_state=1)\n",
    "\n",
    "\n",
    "# 의사결정나무 테스트\n",
    "# dt = DecisionTreeClassifier(max_depth=5)\n",
    "# dt.fit(X_train, y_train)\n",
    "# y_pred = dt.predict(X_test)\n",
    "\n",
    "# submission = pd.DataFrame({\"ID\":X_test.index, \"Outcome\":y_pred})\n",
    "# print(submission)\n",
    "# submission.to_csv(\"01234567890.csv\", index=False)\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=5, min_samples_split=5)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "# print(y_pred)\n",
    "\n",
    "print(f\"정확도는:{accuracy_score(y_test, y_pred):.3f}\")\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T2-3. Adult Census Income Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               0\n",
       "workclass         0\n",
       "fnlwgt            0\n",
       "education         0\n",
       "education.num     0\n",
       "marital.status    0\n",
       "occupation        0\n",
       "relationship      0\n",
       "race              0\n",
       "sex               0\n",
       "capital.gain      0\n",
       "capital.loss      0\n",
       "hours.per.week    0\n",
       "native.country    0\n",
       "income            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "data = pd.read_csv(\"./adult.csv\")\n",
    "# data.info()\n",
    "# data.describe()\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T2-5. Insurance Forecast (Regression) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5956.454717976426\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, mean_squared_error,r2_score, mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "data = pd.read_csv(\"./data/insurance.csv\")\n",
    "# data.info()\n",
    "# data.isnull().sum()\n",
    "y=data[\"charges\"]\n",
    "\n",
    "# y['charges'] = np.log1p(y['charges'])\n",
    "\n",
    "data.drop(\"charges\", axis=1, inplace=True)\n",
    "\n",
    "\n",
    "data=pd.get_dummies(data)\n",
    "X_train, X_test, y_train, y_test=train_test_split(data, y, test_size=0.2, random_state=1)\n",
    "\n",
    "\n",
    "# y_train['charges'] = np.log1p(y_train['charges'])\n",
    "\n",
    "# model = DecisionTreeRegressor(max_depth=5, min_samples_split=5)\n",
    "# model.fit(X_train, y_train)\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred= model.predict(X_test)\n",
    "\n",
    "submission = pd.DataFrame({\"id\":X_test.index, \"charges\":y_pred})\n",
    "submission\n",
    "\n",
    "MSE = mean_squared_error(y_test, y_pred)\n",
    "RMSE=np.sqrt(MSE)\n",
    "print(RMSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. 회귀 모델\n",
    "# 9-1. 선형 회귀(릿지/라쏘)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "model = ElasticNet()\n",
    "\n",
    "# 9-2. 결정나무\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "model = DecisionTreeRegressor(random_state=0)\n",
    "\n",
    "# 9-3. SVM\n",
    "from sklearn.svm import SVR\n",
    "model = SVR()\n",
    "\n",
    "# 9-4. 랜덤포레스트\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor(max_depth=10, n_estimators=100, random_state=0)\n",
    "\n",
    "# 9-5. Ada 부스팅\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "model = AdaBoostClassifier(random_state=0)\n",
    "\n",
    "# 9-6. XG 부스팅\n",
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(497, 2)\n"
     ]
    }
   ],
   "source": [
    "### 캐글 기출 연습\n",
    "X_train = pd.read_csv(\"./data/t2-1-train.csv\")\n",
    "X_test = pd.read_csv(\"./data/t2-1-test.csv\")\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, accuracy_score, mean_squared_error, roc_auc_score\n",
    "\n",
    "ids=X_test[\"id\"]\n",
    "y_train=X_train[\"TravelInsurance\"]\n",
    "X_train.drop([\"id\",\"TravelInsurance\"], axis=1, inplace=True)\n",
    "X_test.drop([\"id\"], axis=1, inplace=True)\n",
    "# print(X_test.shape)\n",
    "columns=[\"Employment Type\", \"GraduateOrNot\", \"FrequentFlyer\", \"EverTravelledAbroad\"]\n",
    "\n",
    "#결측값 확인 \"AnnualIncome\"\n",
    "# print(X_train.isnull().sum())\n",
    "# print(X_test.isnull().sum())\n",
    "\n",
    "X_train[\"AnnualIncome\"]=X_train[\"AnnualIncome\"].fillna(X_train[\"AnnualIncome\"].mean())\n",
    "X_test[\"AnnualIncome\"]=X_test[\"AnnualIncome\"].fillna(X_test[\"AnnualIncome\"].mean())\n",
    "\n",
    "# 데이터 \n",
    "# 타겟값: \"TravelInsurance\"\n",
    "# 없앨것 : \"id\"\n",
    "# 범주형: \"Employment Type\", \"GraduateOrNot\", \"FrequentFlyer\", \"EverTravelledAbroad\"\n",
    "# print(X_train.info())\n",
    "# print(X_test.info())\n",
    "\n",
    "df=pd.concat([X_train,X_test])\n",
    "for cols in columns:\n",
    "    lb = LabelEncoder()\n",
    "    df[cols]=lb.fit_transform(df[cols])\n",
    "\n",
    "\n",
    "mx=MinMaxScaler()\n",
    "mx.fit(df[[\"AnnualIncome\"]])\n",
    "df[\"AnnualIncome\"]=mx.transform(df[[\"AnnualIncome\"]])\n",
    "# print(df)\n",
    "\n",
    "X_train=df[:X_train.shape[0]]\n",
    "X_test=df[X_train.shape[0]:]\n",
    "\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=2022)\n",
    "# print(X_train.shape)\n",
    "# print(y_train.shape)\n",
    "# 랜덤포레스트\n",
    "rf=RandomForestClassifier(n_estimators=500, max_depth=5, random_state=2022)\n",
    "rf.fit(X_tr, y_tr)\n",
    "pred=rf.predict_proba(X_val)\n",
    "pred=pred[:,1]\n",
    "# print(roc_auc_score(y_val, pred))\n",
    "\n",
    "y_pred=rf.predict_proba(X_test)\n",
    "y_pred=y_pred[:,1]\n",
    "\n",
    "# 제출\n",
    "submission = pd.DataFrame({\"id\":ids,\"TravelInsurance\":y_pred})\n",
    "# print(submission.shape)\n",
    "submission.to_csv(\"../datasets/004002519.csv\", index=False)\n",
    "\n",
    "\n",
    "# xgb=XGBClassifier(n_estimators=500, max_depth=5, learning_rate=0.01, objective=\"binary:logistic\")\n",
    "# xgb.fit(X_tr, y_tr, early_stopping_rounds=100, eval_metric=\"auc\", eval_set=[X_val,y_val], verbose=False)\n",
    "# pred=xgb.predict(X_val)\n",
    "# print(accuracy_score(y_val, pred))\n",
    "\n",
    "\n",
    "# xgb=XGBRegressor(n_estimators=300, max_depth=3, learning_rate=0.05, n_jobs=-1)\n",
    "# xgb.fit(X_train, y_train, eval_set = [(X_val, y_val)], early_stopping_rounds=30, verbose=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 빅분기 실기 모의고사 1회차"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/Datamanim/datarepo/main/bank/train.csv')\n",
    "result=(df.age//10*10).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "# 문제 1 마케팅 응답 고객들의 나이를 10살 단위로 변환 했을 때, 가장 많은 인원을 가진 나이대는? (0~9 : 0 , 10~19 : 10)\n",
    "result=(df.age//10*10).value_counts().index[0]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3198\n"
     ]
    }
   ],
   "source": [
    "# 문제 2 가장 많은 나이대 구간의 인원은 몇명인가?\n",
    "result=(df.age//10*10).value_counts()\n",
    "\n",
    "print(result.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "504\n"
     ]
    }
   ],
   "source": [
    "# 나이가 25살 이상 29살 미만인 응답 고객들중 housing컬럼의 값이 yes인 고객의 수는?\n",
    "result=df[(df[\"age\"]>=25)&(df[\"age\"]<29)&(df[\"housing\"]==\"yes\")].shape[0]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job\n"
     ]
    }
   ],
   "source": [
    "# 4번문제 numeric한 값을 가지지 않은 컬럼들중 unique한 값을 가장 많이 가지는 컬럼은?\n",
    "lst= [] \n",
    "for col in df.select_dtypes(exclude='int'):\n",
    "    target = df[col]\n",
    "    lst.append([col,target.nunique()])\n",
    "\n",
    "result = pd.DataFrame(lst).sort_values(1,ascending=False).values[0][0]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3473.73\n"
     ]
    }
   ],
   "source": [
    "# 5번 balance 컬럼값들의 평균값 이상을 가지는 데이터를 ID값을 기준으로 내림차순 정렬했을때 상위 100개 데이터의 balance값의 평균은?\n",
    "means=df[\"balance\"].mean()\n",
    "result=df[df[\"balance\"]>=means].sort_values(by=\"ID\", ascending=False).iloc[:100]\n",
    "results=result[\"balance\"].mean()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 'may')\n"
     ]
    }
   ],
   "source": [
    "# 6번 가장 많은 광고를 집행했던 날짜는 언제인가? (데이터 그대로 일(숫자),달(영문)으로 표기)\n",
    "result = df[['day','month']].value_counts().index[0]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1961131989955902\n"
     ]
    }
   ],
   "source": [
    "# 7번 데이터의 job이 unknown 상태인 고객들의 age 컬럼 값의 정규성을 검정하고자 한다. 샤피로 검정의 p-value값을 구하여라\n",
    "from scipy.stats import shapiro\n",
    "result = shapiro(df[df.job =='unknown'].age)[1]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10198734763981462\n"
     ]
    }
   ],
   "source": [
    "# 8번 age와 balance의 상관계수를 구하여라\n",
    "cor=df[[\"age\",\"balance\"]].corr().iloc[0,1]\n",
    "print(cor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13829</td>\n",
       "      <td>29</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>18254</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>11</td>\n",
       "      <td>may</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22677</td>\n",
       "      <td>26</td>\n",
       "      <td>services</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>512</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>jun</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10541</td>\n",
       "      <td>30</td>\n",
       "      <td>management</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>135</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>14</td>\n",
       "      <td>aug</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13689</td>\n",
       "      <td>41</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>30</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>10</td>\n",
       "      <td>jul</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11304</td>\n",
       "      <td>27</td>\n",
       "      <td>admin.</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>321</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2</td>\n",
       "      <td>sep</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12865</th>\n",
       "      <td>14023</td>\n",
       "      <td>47</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>1167</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>30</td>\n",
       "      <td>apr</td>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "      <td>5</td>\n",
       "      <td>failure</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12866</th>\n",
       "      <td>17259</td>\n",
       "      <td>31</td>\n",
       "      <td>unknown</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>111</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>21</td>\n",
       "      <td>nov</td>\n",
       "      <td>2</td>\n",
       "      <td>93</td>\n",
       "      <td>2</td>\n",
       "      <td>failure</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12867</th>\n",
       "      <td>15200</td>\n",
       "      <td>37</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>single</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>1316</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>18</td>\n",
       "      <td>nov</td>\n",
       "      <td>1</td>\n",
       "      <td>172</td>\n",
       "      <td>2</td>\n",
       "      <td>failure</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12868</th>\n",
       "      <td>13775</td>\n",
       "      <td>42</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>479</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>28</td>\n",
       "      <td>may</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12869</th>\n",
       "      <td>20137</td>\n",
       "      <td>24</td>\n",
       "      <td>services</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>16</td>\n",
       "      <td>may</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12870 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  age         job  marital  education default  balance housing  \\\n",
       "0      13829   29  technician   single   tertiary      no    18254      no   \n",
       "1      22677   26    services   single  secondary      no      512     yes   \n",
       "2      10541   30  management   single  secondary      no      135      no   \n",
       "3      13689   41  technician  married    unknown      no       30     yes   \n",
       "4      11304   27      admin.   single  secondary      no      321      no   \n",
       "...      ...  ...         ...      ...        ...     ...      ...     ...   \n",
       "12865  14023   47  technician  married  secondary      no     1167     yes   \n",
       "12866  17259   31     unknown  married  secondary      no      111      no   \n",
       "12867  15200   37  unemployed   single   tertiary      no     1316     yes   \n",
       "12868  13775   42  management  married   tertiary      no      479     yes   \n",
       "12869  20137   24    services   single  secondary      no        0      no   \n",
       "\n",
       "      loan   contact  day month  campaign  pdays  previous poutcome    y  \n",
       "0       no  cellular   11   may         2     -1         0  unknown   no  \n",
       "1      yes   unknown    5   jun         3     -1         0  unknown   no  \n",
       "2       no  cellular   14   aug         2     -1         0  unknown   no  \n",
       "3       no  cellular   10   jul         1     -1         0  unknown   no  \n",
       "4      yes   unknown    2   sep         1     -1         0  unknown   no  \n",
       "...    ...       ...  ...   ...       ...    ...       ...      ...  ...  \n",
       "12865   no  cellular   30   apr         1     87         5  failure  yes  \n",
       "12866   no  cellular   21   nov         2     93         2  failure  yes  \n",
       "12867   no  cellular   18   nov         1    172         2  failure   no  \n",
       "12868   no   unknown   28   may         2     -1         0  unknown   no  \n",
       "12869   no   unknown   16   may         1     -1         0  unknown   no  \n",
       "\n",
       "[12870 rows x 17 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2831050228310502\n"
     ]
    }
   ],
   "source": [
    "#  10번 각 job에 따라 divorced/married 인원의 비율을 확인 했을 때 그 값이 가장 높은 값은?\n",
    "t = df.groupby(['job','marital']).size().reset_index()\n",
    "pivotdf = t.pivot_table(index='job',columns='marital')[0]\n",
    "pivotdf = pivotdf.fillna(0)\n",
    "pivotdf['ratio'] = pivotdf['divorced'] / pivotdf['married']\n",
    "\n",
    "result = pivotdf.sort_values('ratio').ratio.values[-1]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 회귀 문제 연습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9425721695222399\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "X_train = pd.read_csv(\"./data/t2-2-X_train.csv\")\n",
    "X_test= pd.read_csv(\"./data/t2-2-X_test.csv\")\n",
    "y_train = pd.read_csv(\"./data/t2-2-y_train.csv\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import accuracy_score, r2_score, mean_squared_error, confusion_matrix, mean_absolute_error\n",
    "\n",
    "ids=X_test[\"Serial No.\"]\n",
    "# 데이터 확인\n",
    "# print(X_train.info())\n",
    "# print(X_test.info())\n",
    "# print(y_train)\n",
    "# print(X_train.isnull().sum())\n",
    "# print(X_test.isnull().sum())\n",
    "\n",
    "X_train=X_train.drop([\"Serial No.\"], axis=1)\n",
    "X_test=X_test.drop([\"Serial No.\"], axis=1)\n",
    "y_train=y_train.drop([\"Serial No.\"], axis=1)\n",
    "\n",
    "cols=X_train.columns\n",
    "\n",
    "st= StandardScaler()\n",
    "st.fit(X_train)\n",
    "X_train_st=st.transform(X_train)\n",
    "\n",
    "st.fit(X_test)\n",
    "X_test_st=st.transform(X_test)\n",
    "\n",
    "X_train=pd.DataFrame(X_train_st,columns=cols)\n",
    "X_test=pd.DataFrame(X_test_st, columns=cols)\n",
    "\n",
    "X_tr,X_val, y_tr, y_val = train_test_split(X_train,y_train, test_size=0.2, random_state=2022)\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(X_test.shape)\n",
    "\n",
    "# rf = RandomForestRegressor(n_estimators=500, max_depth=10, random_state=2022)\n",
    "# rf.fit(X_tr,y_tr)\n",
    "# pred=rf.predict(X_val)\n",
    "# print(r2_score(y_val,pred))\n",
    "\n",
    "# y_pred=rf.predict(X_test)\n",
    "\n",
    "\n",
    "# DecisionTreeRegressor\n",
    "# dc = DecisionTreeRegressor(max_depth=10, random_state=2022)\n",
    "# dc.fit(X_tr, y_tr)\n",
    "# pred=dc.predict(X_val)\n",
    "# print(r2_score(y_val, pred))\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import r2_score\n",
    "xgb_model = xgb.XGBRegressor(n_estimators=300, max_depth=3, learning_rate=0.05, n_jobs=-1)\n",
    "xgb_model.fit(X_train, y_train, eval_set = [(X_val, y_val)], early_stopping_rounds=30, verbose=0)\n",
    "pred=xgb_model.predict(X_val)\n",
    "print(r2_score(y_val, pred))\n",
    "\n",
    "\n",
    "# submission = pd.DataFrame({\"Serial No.\":ids,\"chance of Admit\":y_pred})\n",
    "# submission.to_csv(\"004002519.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7515004974024538\n"
     ]
    }
   ],
   "source": [
    "# 작업형 2유형 문제\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, mean_squared_error\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "train= pd.read_csv('https://raw.githubusercontent.com/Datamanim/datarepo/main/bank/train.csv')\n",
    "test= pd.read_csv('https://raw.githubusercontent.com/Datamanim/datarepo/main/bank/test.csv')\n",
    "train[\"y\"]=train[\"y\"].apply(lambda x: 1 if(x==\"yes\") else 0)\n",
    "\n",
    "# 데이터 확인\n",
    "# train.info()\n",
    "# test.info()\n",
    "y=train[\"y\"]\n",
    "ids=test[\"ID\"]\n",
    "\n",
    "\n",
    "# print(test.isnull().sum())\n",
    "train.drop([\"ID\",\"day\",\"month\",\"y\"], axis=1, inplace=True)\n",
    "test.drop([\"ID\",\"day\",\"month\"], axis=1, inplace=True)\n",
    "df=pd.concat([train, test])\n",
    "colums=[\"job\", \"marital\",\"education\",\"default\",\"housing\",\"loan\",\"contact\",\"poutcome\"]\n",
    "for cols in colums:\n",
    "    lb = LabelEncoder()\n",
    "    df[cols]=lb.fit_transform(df[cols])\n",
    "mx=MinMaxScaler()\n",
    "mx.fit(df[[\"pdays\"]])\n",
    "df[\"pdays\"]=mx.transform(df[[\"pdays\"]])\n",
    "\n",
    "train=df.iloc[:len(train)]\n",
    "test=df.iloc[len(train):]\n",
    "\n",
    "X_train, X_val, y_train,y_val =train_test_split(train,y,test_size=0.2, random_state=2022)\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(random_state=2022, max_depth=10, n_estimators=500)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "pred=rf.predict_proba(X_val)\n",
    "pred=pred[:,1]\n",
    "print(roc_auc_score(y_val, pred))\n",
    "\n",
    "\n",
    "\n",
    "# y_pred=rf.predict_proba(test)\n",
    "# y_pred=y_pred[:,1]\n",
    "\n",
    "\n",
    "# submission = pd.DataFrame({\"id\":ids,\"y\":y_pred})\n",
    "# submission.to_csv(\"./data/004002519.csv\", index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 빅분기 실기 모의고사 2회차"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
